1.Convolutional layer:

tf.nn.conv2d(
    input,
    filter,
    strides,
    padding,
    use_cudnn_on_gpu=True,
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
Computes a 2-D convolution given 4-D input and filter tensors.

Given an input tensor of shape [batch, in_height, in_width, in_channels] and a filter / kernel tensor of shape [filter_height, filter_width, in_channels, out_channels], this op performs the following:

Flattens the filter to a 2-D matrix with shape [filter_height * filter_width * in_channels, output_channels].
Extracts image patches from the input tensor to form a virtual tensor of shape [batch, out_height, out_width, filter_height * filter_width * in_channels].
For each patch, right-multiplies the filter matrix and the image patch vector.
In detail, with the default NHWC format,

output[b, i, j, k] =
    sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *
                    filter[di, dj, q, k]
Must have strides[0] = strides[3] = 1. For the most common case of the same horizontal and vertices strides, strides = [1, stride, stride, 1].

Args:
input: A Tensor. Must be one of the following types: half, bfloat16, float32, float64. A 4-D tensor. The dimension order is interpreted according to the value of data_format, see below for details.
filter: A Tensor. Must have the same type as input. A 4-D tensor of shape [filter_height, filter_width, in_channels, out_channels]
strides: A list of ints. 1-D tensor of length 4. The stride of the sliding window for each dimension of input. The dimension order is determined by the value of data_format, see below for details.
padding: A string from: "SAME", "VALID". The type of padding algorithm to use.
use_cudnn_on_gpu: An optional bool. Defaults to True.
data_format: An optional string from: "NHWC", "NCHW". Defaults to "NHWC". Specify the data format of the input and output data. With the default format "NHWC", the data is stored in the order of: [batch, height, width, channels]. Alternatively, the format could be "NCHW", the data storage order of: [batch, channels, height, width].
dilations: An optional list of ints. Defaults to [1, 1, 1, 1]. 1-D tensor of length 4. The dilation factor for each dimension of input. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of data_format, see above for details. Dilations in the batch and depth dimensions must be 1.
name: A name for the operation (optional).
Returns:
A Tensor. Has the same type as input.

结论：从input到output（第四维度k来自filter的out_channels），每个节点Node的输入只是上一层（输入层）的一小块，并对每个小块进行更深入的分析，所以每个节点深度会增加；。
思考1：why zero-padding,or tune stride? 
     回答：被filter扫描后形成的矩阵可能尺寸变小，所以为了keep矩阵尺寸，要么zero-padding,要么tune stride
           use zero-pading:OutputArray_width=ceil((InputArray_width-filter_width)/stride_width) #ceil向上取整
                           OutputArray_lenght.........same as pre
           no use zero-pading:OutputArray_width=ceil((InputArray_width-filter_width+1)/stride_width) #ceil向上取整
                              OutputArray_lenght......same as pre

思考2:图像上内容位置不一样，结果是否受影响？
     回答：不会受影响，每个卷积层中使用的filter参数都是一样的，直观的讲，共享过滤器参数可以使图像内容不受
                       位置影响，无论图像上的内容在那个位置，经过卷积层和结果不受影响
思考3:参数个数有多少？
     回答：只与filter的尺寸，深度。以及当前层节点矩阵的深度有关
          例如：输入层矩阵的维度32x32x3，第一层卷积层使用尺寸5x5大小，深度为16的filter，参数有5x5x3x16个
          filter:[filter_height, filter_width, in_channels, out_channels],那么
          total filter_height*filter_width*out_channels*in_channels个
          filter:[filter_height, filter_width, in_channels, out_channels],
                   total filter_height*filter_width*out_channels*in_channels+个 （加上偏置项）
思考4:strides怎么设置？
    回答：strides第一维和最后一维都为1，原因是卷积层的步长只对矩阵的长和宽有效，卷积层使用的filter是横跨整个深度的，filter只在长和宽两个维度上移动。
思考5:这一层的输出矩阵大小如何计算？
    回答：尺寸（长，宽） 如思考1
         深度同filter深度


2.Pooling layer

tf.nn.avg_pool
tf.nn.avg_pool(
    value,
    ksize,
    strides,
    padding,
    data_format='NHWC',
    name=None
)

Performs the average pooling on the input.

Each entry in output is the mean of the corresponding size ksize window in value.

Args:
value: A 4-D Tensor of shape [batch, height, width, channels] and type float32, float64, qint8, quint8, or qint32.
ksize: A list or tuple of 4 ints. The size of the window for each dimension of the input tensor.
strides: A list or tuple of 4 ints. The stride of the sliding window for each dimension of the input tensor.
padding: A string, either 'VALID' or 'SAME'. The padding algorithm. See the comment here
data_format: A string. 'NHWC' and 'NCHW' are supported.
name: Optional name for the operation.
Returns:
A Tensor with the same type as value. The average pooled output tensor.

思考1:池化层作用是？
   答：缩小矩阵的尺寸（矩阵的长度和宽度），（不会改变矩阵深度），从而减少了最后连接层的参数，加快了计算速度，也防止了过拟合
思考2:池化层与卷积层参数形式，意义一致么？
   答：
      第一个参数都是传入一个四维矩阵作为当前层节点矩阵，格式上和conv2d中一致。
      第二个参数给出了filter尺寸，一个长度为4的一维数组，但第一个和最后一个值都为1，意味着不能跨不同输入样例，也不能跨节点矩阵深度 进行扫描。
              实际使用最多的filter尺寸是[1,2,2,1],[1,3,3,1]
      第三个参数步长conv2d中意义一致，而且第一维和最后一维都只能为1
思考3:一张图片经过 卷积层处理，池化层处理 直观上变成什么样？
    答：卷积层将神经网络中的一小块进行更深入的分析得到抽象度更高的特征；
       池化层可以直观变现为把一个高分辨率的图片变成一个较低分辨率的图片


